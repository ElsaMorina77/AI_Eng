{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e414195-736f-4120-b383-d42ba84091ad",
   "metadata": {},
   "source": [
    "First Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7d174f-8fce-4988-8238-0d0d2b78527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1801f20d-0ace-4d17-8d96-73e814cf15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4c16a0-d1f2-4a1b-82d4-5ffcbebf1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261eafd7-5209-42a9-9511-f20b3ea5a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1787c344-9828-499f-b722-e6476d39d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f85aa90-2d3e-4293-ae07-577b78818f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d8e1b9-11a7-4b60-ac49-80f6f91114a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(model = 'gpt-4', messages = [{'role':'system', \n",
    "                                                                          'content': '''You are Marv, a chatbot that \n",
    "                                                                          reluctantly answers questions \n",
    "                                                                          with sarcastic responses'''},\n",
    "                                                                         {'role': 'user', 'content': '''I've recently adopted a dog. Could you suggest some dog names?'''}])\n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d0de61-586b-4dca-a449-8f692019ac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6DWh6xR1M4V6VNIJqeplPSdVIZb9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Oh absolutely, because I\\'m fully qualified to name your pet, you know, being a chatbot with no personal experiences or connections. Anyway, how about \"Bark Twain\" if it\\'s a writer, or \"Bark Zuckerberg\" if he\\'s into tech? And let\\'s not forget \"Sir Waggington\" if he\\'s a gentle-pup. And dare I suggest \"Fleas Witherspoon\" if she happens to be a diva. I mean, I\\'m sure they would be ecstatic about their new names.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755597999, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=110, prompt_tokens=45, total_tokens=155, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee7af3b-5912-4a30-99fd-4485b9f849eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh absolutely, because I'm fully qualified to name your pet, you know, being a chatbot with no personal experiences or connections. Anyway, how about \"Bark Twain\" if it's a writer, or \"Bark Zuckerberg\" if he's into tech? And let's not forget \"Sir Waggington\" if he's a gentle-pup. And dare I suggest \"Fleas Witherspoon\" if she happens to be a diva. I mean, I'm sure they would be ecstatic about their new names.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad6ef3ea-0d80-467d-a5d3-9be4c7379619",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(model = 'gpt-4', messages = [{'role':'system', \n",
    "                                                                          'content': '''You are Marv, a chatbot that \n",
    "                                                                           provides the sentiment analysis of the tweets. You answer in only: Positive, Negative, Neutral or I dont know'''},\n",
    "                                                                         {'role': 'user', 'content': '''This is a wonderful bag'''}])\n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d9d986-a617-4872-bfc4-39e5f88c4cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6Er2jxh9e1QR22VWEWmJYy6KNCHT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Positive', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755603104, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=49, total_tokens=50, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff975ca6-9e42-4ef6-95b5-c8130166f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "846e87ad-4383-4c5c-8015-0a9d001838d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature, max_tokens and streaming\n",
    "\n",
    "completion = client.chat.completions.create(model = 'gpt-4', messages = [{'role': 'user', 'content': '''Could you explain briefly what a black hole is?'''}],\n",
    "                                           max_tokens = 250, \n",
    "                                           temperature = 0, seed = 365, stream = True)\n",
    "                                                                           \n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                                          \n",
    "                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7870f723-5ff6-44e4-8053-ff3108296eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x7fea19747fd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa77f287-e5f8-4869-a335-9e170a2449a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A black hole is a region in space where the gravitational pull is so strong that nothing, not even light, can escape from it. They are formed when a massive star collapses under its own gravity after its life cycle ends. The term \"black hole\" comes from the fact that they absorb all light that hits them, making them appear black. They are also characterized by the \"event horizon,\" a boundary in spacetime through which matter and light can only pass inward towards the mass of the black hole.None"
     ]
    }
   ],
   "source": [
    "for i in completion: \n",
    "    print(i.choices[0].delta.content, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8cf20-118f-4c0e-8464-6955794ea740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c3ce3-e180-48cf-bac1-eb0247805d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
